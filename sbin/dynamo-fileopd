#!/usr/bin/env python

#################################################################################
### dynamo-fileopd ##############################################################
###
### File operations daemon that acts on the transfer and deletion tasks created
### by the Dynamo file operations manager (FOM). Tasks are listed in MySQL tables
### ("queues"). This daemon is responsible for picking up tasks from the queues
### and executing gfal2 copies or deletions, while driving the task state machine.
### Parallel operations are implemented using multiprocessing.Pool. One Pool is
### created per source-destination pair (target site) in transfers (deletions).
### Because each gfal2 operation reserves a network port, the machine must have
### sufficient number of open ports for this daemon to operate.
### Task state machine:
### Tasks arrive at the queue in 'new' state. The possible transitions are
###  new -> queued    ... When the task is added to the operation pool
###  queued -> done   ... When the task operation succeeded
###  queued -> failed ... When the task operation failed
###  new -> -         ... When the task is cancelled by the FOM
###  queued -> -      ... When the task is cancelled by the FOM
#################################################################################

import os
import sys
import pwd
import time
import threading
import signal
import multiprocessing
import multiprocessing.managers
import logging
import logging.handlers
import tempfile
import gfal2
import cStringIO

## Need to have a global signal converter that subprocesses can unset blocking
from dynamo.utils.signaling import SignalConverter
signal_converter = SignalConverter()

## Specify error codes that should not be considered as errors

transfer_nonerrors = {
    17: 'Destination file exists.' # for a transfer task, 17 means that file exists at the destination
                                   # - should check file size and checksum with context.stat(dest_pfn)
}

deletion_nonerrors = {
    2: 'Target file already removed.'
}

def pre_exec():
    """Function executed in each subprocess before everything else"""

    signal_converter.unset(signal.SIGTERM)
    signal_converter.unset(signal.SIGHUP)

def transfer(task_id, queued_ids, queued_ids_lock, src_pfn, dest_pfn, params_config):
    """
    Transfer task worker process
    @param task_id         Task id in the queue.
    @param queued_ids      List (actually multiprocessing proxy for a shared-memory list) of active task ids.
    @param queued_ids_lock Lock for the ids list
    @param src_pfn         Source PFN
    @param dest_pfn        Destination PFN
    @param params_config   Configuration parameters used to create GFAL2 transfer parameters.

    @return  (exit code, start time, finish time, error message, log string)
    """

    with queued_ids_lock:
        if task_id not in queued_ids:
            # task was cancelled
            return -1, 0, 0, '', ''

    try:
        params = gfal2.Gfal2Context.transfer_parameters()
        # Create parent directories at the destination
        params.create_parent = True
        # Overwrite the destination if file already exists (otherwise throws an error)
        params.overwrite = params_config['overwrite']
        params.set_checksum(*params_config['checksum'])
        params.timeout = params_config['transfer_timeout'] # we probably want this to be file size dependent
    
    except Exception as exc:
        # multiprocessing pool cannot handle certain exceptions - convert to string
        raise Exception(str(exc))

    return gfal_exec('filecopy', (params, src_pfn, dest_pfn), transfer_nonerrors)

def delete(task_id, queued_ids, queued_ids_lock, pfn):
    """
    Deletion task worker process
    @param task_id        Task id in the queue.
    @param queued_ids     List (actually multiprocessing proxy for a shared-memory list) of active task ids.
    @param queued_ids_lock Lock for the ids list
    @param pfn            Target PFN

    @return  (exit code, start time, finish time, error message, log string)
    """

    with queued_ids_lock:
        if task_id not in queued_ids:
            # task was cancelled
            return -1, 0, 0, '', ''

    return gfal_exec('unlink', (pfn,), deletion_nonerrors)

def gfal_exec(method, args, nonerrors):
    """
    GFAL2 execution function
    @param method     Name of the Gfal2Context method to execute.
    @param args       Tuple of arguments to pass to the method
    @param nonerrors  Dictionary of error code translation for non-errors.

    @return  (exit code, start time, finish time, error message, log string)
    """

    start_time = 0
    finish_time = 0
    log = ''

    for attempt in xrange(5):
        # gfal2 knows to write to the logger. Redirect to StringIO and dump the full log at the end.
        stream = cStringIO.StringIO()
        LOG.handlers.pop()
        handler = logging.StreamHandler(stream)
        handler.setFormatter(logging.Formatter(fmt = '%(asctime)s: %(message)s'))
        LOG.addHandler(handler)

        start_time = int(time.time())
    
        try:
            gfal2.set_verbose(gfal2.verbose_level.verbose)

            context = gfal2.creat_context()
            getattr(gfal2.Gfal2Context, method)(context, *args)

            finish_time = int(time.time())
        
        except gfal2.GError as err:
            exitcode, msg = err.code, str(err)

            if err.code == 70:
                # port bind failure - seems to be an artefact of using multiple gfal-copy in parallel
                # usually it finds a good port after a retry
                continue

            if err.code in nonerrors:
                return 0, start_time, int(time.time()), nonerrors[err.code], ''

        except Exception as exc:
            exitcode, msg = -1, str(exc)
    
        else:
            exitcode, msg = 0, ''
    
        finally:
            log_tmp = stream.getvalue().strip()

        # give a nice indent to each line
        log = ''.join('  %s\n' % line for line in log_tmp.split('\n'))
    
        stream.close()

        break

    # all three variables would be defined even when all attempts are exhausted
    return exitcode, start_time, finish_time, msg, log


class PoolManager(object):
    """
    Base class for managing one task pool. Asynchronous results of the tasks are collected
    in collect_results() running as a separate thread, automatically started when the first
    task is added to the pool
    """

    db = None
    stop_flag = None

    def __init__(self, name, optype, opformat, task, max_concurrent):
        """
        @param name           Name of the instance. Used in logging.
        @param optype         'transfer' or 'deletion'.
        @param opformat       Format string used in logging.
        @param task           Task function.
        @param max_concurrent Maximum number of concurrent processes in the pool.
        """

        self.name = name
        self.optype = optype
        self.opformat = opformat
        self.task = task

        self._pool = multiprocessing.Pool(max_concurrent, initializer = pre_exec)
        self._results = []
        self._collector_thread = None
        self._closed = False

    def add_task(self, tid, *args):
        """
        Add a task to the pool and start the results collector.
        """

        if self._closed:
            raise RuntimeError('PoolManager %s is closed' % self.name)

        # TransferPoolManager or DeletionPoolManager
        self_cls = type(self)

        sql = 'UPDATE `standalone_{op}_queue` SET `status` = \'queued\' WHERE `id` = %s'.format(op = self.optype)
        with self_cls.queued_ids_lock:
            PoolManager.db.query(sql, tid)
            self_cls.queued_ids.append(tid)

        opstring = self.opformat.format(*args)
        LOG.info('%s: %s %s', self.name, self.optype, opstring)

        proc_args = (tid, self_cls.queued_ids, self_cls.queued_ids_lock) + args
        async_result = self._pool.apply_async(self.task, proc_args)
        self._results.append((tid, async_result) + args)

        if self._collector_thread is None:
            self.start_collector()

    def process_result(self, result_tuple):
        """
        Process the result of a completed task.
        """

        delim = '--------------'
        sql = 'UPDATE `standalone_{op}_queue` SET `status` = %s, `exitcode` = %s, `start_time` = FROM_UNIXTIME(%s), `finish_time` = FROM_UNIXTIME(%s) WHERE `id` = %s'.format(op = self.optype)

        tid, result = result_tuple[:2]
        args = result_tuple[2:]

        exitcode, start_time, finish_time, msg, log = result.get()

        optime = finish_time - start_time
        opstring = self.opformat.format(*args)

        if exitcode == -1:
            LOG.info('%s: cancelled %s %s', self.name, self.optype, opstring)
            return
        elif exitcode == 0:
            LOG.info('%s: succeeded %s (%d s) %s\n%s\n%s%s', self.name, self.optype, optime, opstring, delim, log, delim)
            status = 'done'
        else:
            LOG.info('%s: failed %s (%d s, %d: %s) %s\n%s\n%s%s', self.name, self.optype, optime, exitcode, msg, opstring, delim, log, delim)
            status = 'failed'

        PoolManager.db.query(sql, status, exitcode, start_time, finish_time, tid)

    def ready_for_recycle(self):
        """
        Check if this pool manager can be shut down. Managers should be shut down whenever
        possible to keep the resource (threads and subprocesses) usage down and also to
        adjust the concurrency on each link as needed.
        """

        if self._closed:
            return True

        if self._collector_thread is None:
            return True

        if self._collector_thread.is_alive():
            return False

        if PoolManager.stop_flag.is_set():
            LOG.warning('Terminating pool %s' % self.name)
            self._pool.terminate()

        self._pool.close()
        self._pool.join()

        self._collector_thread.join()

        self._closed = True

        return True

    def start_collector(self):
        self._collector_thread = threading.Thread(target = self.collect_results, name = self.name)
        self._collector_thread.start()

    def collect_results(self):
        while len(self._results) != 0:
            ir = 0
            while ir != len(self._results):
                if PoolManager.stop_flag.is_set():
                    return
    
                if not self._results[ir][-1].ready():
                    ir += 1
                    continue
    
                self.process_result(self._results.pop(ir))
    
            is_set = stop_flag.wait(5)
            if is_set: # True if Python 2.7 + flag is set
                return

class TransferPoolManager(PoolManager):
    queued_ids = None
    queued_ids_lock = None

    def __init__(self, src, dest, max_concurrent):
        name = '%s-%s' % (src, dest)
        opformat = '{0} -> {1}'
        PoolManager.__init__(self, name, 'transfer', opformat, transfer, max_concurrent)

class DeletionPoolManager(PoolManager):
    queued_ids = None
    queued_ids_lock = None

    def __init__(self, site, max_concurrent):
        opformat = '{0}'
        PoolManager.__init__(self, site, 'deletion', opformat, delete, max_concurrent)


if __name__ == '__main__':
    ## Read server config (should be readable only to root)
    from dynamo.dataformat import Configuration
    from dynamo.core.serverutils import BANNER
    from dynamo.utils.log import log_exception
    from dynamo.utils.interface.mysql import MySQL
    
    try:
        config_path = os.environ['DYNAMO_SERVER_CONFIG']
    except KeyError:
        config_path = '/etc/dynamo/server_config.json'
    
    config = Configuration(config_path)
    
    ## Set up logging (write to stderr unless path is given)
    log_level = getattr(logging, config.logging.level.upper())
    log_format = '%(asctime)s:%(levelname)s:%(name)s: %(message)s'
    
    LOG = logging.getLogger()
    LOG.setLevel(log_level)
    if config.logging.get('path', ''):
        log_handler = logging.handlers.RotatingFileHandler(config.logging.path + '/fod.log', maxBytes = 10000000, backupCount = 100)
    else:
        log_handler = logging.StreamHandler()
    LOG.addHandler(log_handler)
    
    ## Print some nice banner before we start logging with the timestamp format
    LOG.critical(BANNER)
    
    log_handler.setFormatter(logging.Formatter(fmt = log_format))

    ## Set the effective user id to config.user
    try:
        pwnam = pwd.getpwnam(config.user)
        os.setegid(pwnam.pw_gid)
        os.seteuid(pwnam.pw_uid)
    except OSError:
        LOG.warning('Cannot switch uid to %s (%d).', config.user, pwd.getpwnam(config.user).pw_uid)

    ## File operations config
    fileop_config = config.file_operations
    
    ## Set up operational parameters
    # We want to make these parameters dynamic in the future
    # (which means we'll have to create a new table that records the site names for each batch)
    max_concurrent = fileop_config.daemon.max_parallel_links
    checksum_algo = fileop_config.daemon.get('checksum', '')
    transfer_timeout = fileop_config.daemon.transfer_timeout
    overwrite = fileop_config.daemon.get('overwrite', False)

    if 'gfal2_verbosity' in fileop_config.daemon:
        gfal2.set_verbose(getattr(gfal2.verbose_level, fileop_config.daemon.gfal2_verbosity.lower()))

    params_config = {
        'transfer_nstreams': 1,
        'transfer_timeout': transfer_timeout,
        'overwrite': overwrite
    }

    if checksum_algo:
        # Available checksum algorithms: crc32, adler32, md5
        params_config['checksum'] = (gfal2.checksum_mode.both, checksum_algo, '')
    else:
        params_config['checksum'] = (gfal2.checksum_mode.none, '', '')

    ## Set up a handle to the DB
    db = MySQL(fileop_config.manager.db.db_params)
  
    ## Convert SIGTERM and SIGHUP into KeyboardInterrupt (SIGINT already is)
    signal_converter._logger = LOG
    signal_converter.set(signal.SIGTERM)
    signal_converter.set(signal.SIGHUP)

    ## Create a shared-memory manager to keep a list of queued tasks
    task_id_manager = multiprocessing.managers.SyncManager()
    task_id_manager.start()
    queued_transfer_ids = task_id_manager.list()
    transfer_ids_lock = task_id_manager.Lock()
    queued_deletion_ids = task_id_manager.list()
    deletion_ids_lock = task_id_manager.Lock()

    TransferPoolManager.queued_ids = queued_transfer_ids
    TransferPoolManager.queued_ids_lock = transfer_ids_lock
    DeletionPoolManager.queued_ids = queued_deletion_ids
    DeletionPoolManager.queued_ids_lock = deletion_ids_lock

    ## Collect PoolManagers
    managers = {}

    ## Flag to stop the managers
    stop_flag = threading.Event()

    ## Set the pool manager statics
    PoolManager.db = db
    PoolManager.stop_flag = stop_flag

    ## Pool manager getters
    def get_transfer_manager(src, dest, max_concurrent):
        try:
            return managers[(src, dest)]
        except KeyError:
            managers[(src, dest)] = TransferPoolManager(src, dest, max_concurrent)
            return managers[(src, dest)]

    def get_deletion_manager(site, max_concurrent):
        try:
            return managers[site]
        except KeyError:
            managers[site] = DeletionPoolManager(site, max_concurrent)
            return managers[site]

    ## Start loop
    try:
        # If the previous cycle ended with a crash, there may be some dangling tasks in the queued state
        sql = 'UPDATE `standalone_deletion_queue` SET `status` = \'new\' WHERE `status` = \'queued\''
        db.query(sql)
        sql = 'UPDATE `standalone_transfer_queue` SET `status` = \'new\' WHERE `status` = \'queued\''
        db.query(sql)

        deletion_first_wait = True
        transfer_first_wait = True

        while True:
            ## Create deletion tasks (batched by site)
            if deletion_first_wait:
                LOG.info('Creating deletion tasks.')
                deletion_first_wait = False
        
            sql = 'SELECT q.`id`, a.`file`, b.`site` FROM `standalone_deletion_queue` AS a'
            sql += ' INNER JOIN `deletion_queue` AS q ON q.`id` = a.`id`'
            sql += ' INNER JOIN `standalone_deletion_batches` AS b ON b.`batch_id` = q.`batch_id`'
            sql += ' WHERE a.`status` = \'new\''
            sql += ' ORDER BY b.`site`, q.`id`'
        
            _site = ''
            for tid, pfn, site in db.query(sql):
                if site != _site:
                    _site = site
                    pool_manager = get_deletion_manager(site, max_concurrent)

                pool_manager.add_task(tid, pfn)

                deletion_first_wait = True

            ## Queued tasks may be deleted by FOM - try cancelling the tasks using the task id list
            sql = 'SELECT `id` FROM `standalone_deletion_queue` WHERE `status` = \'queued\''
            with deletion_ids_lock:
                del queued_deletion_ids[:]
                queued_deletion_ids.extend(db.xquery(sql))

            ## Create transfer tasks (batched by site)
            if transfer_first_wait:
                LOG.info('Creating transfer tasks.')
                transfer_first_wait = False

            sql = 'SELECT q.`id`, a.`source`, a.`destination`, b.`source_site`, b.`destination_site` FROM `standalone_transfer_queue` AS a'
            sql += ' INNER JOIN `transfer_queue` AS q ON q.`id` = a.`id`'
            sql += ' INNER JOIN `standalone_transfer_batches` AS b ON b.`batch_id` = q.`batch_id`'
            sql += ' WHERE a.`status` = \'new\''
            sql += ' ORDER BY b.`source_site`, b.`destination_site`, q.`id`'
        
            _link = None
            for tid, src_pfn, dest_pfn, ssite, dsite in db.query(sql):
                if (ssite, dsite) != _link:
                    _link = (ssite, dsite)
                    pool_manager = get_transfer_manager(ssite, dsite, max_concurrent)
        
                pool_manager.add_task(tid, src_pfn, dest_pfn, params_config)

                transfer_first_wait = True

            ## See above
            sql = 'SELECT `id` FROM `standalone_transfer_queue` WHERE `status` = \'queued\''
            with transfer_ids_lock:
                del queued_transfer_ids[:]
                queued_transfer_ids.extend(db.xquery(sql))
        
            ## Recycle threads
            for key, manager in managers.items():
                if manager.ready_for_recycle():
                    managers.pop(key)

            time.sleep(30)

    except KeyboardInterrupt:
        pass

    except:
        log_exception(LOG)

    finally:
        stop_flag.set()

        try:
            # try to clean up
            sql = 'UPDATE `standalone_deletion_queue` SET `status` = \'new\' WHERE `status` = \'queued\''
            db.query(sql)
            sql = 'UPDATE `standalone_transfer_queue` SET `status` = \'new\' WHERE `status` = \'queued\''
            db.query(sql)
        except:
            pass

    while True:
        # PoolManagers will terminate automatically once stop_flag is set
        for key, manager in managers.items():
            if manager.ready_for_recycle():
                managers.pop(key)

        if len(managers) != 0:
            LOG.info('Number of pools: %d', len(managers))
            time.sleep(1)
        else:
            break

    LOG.info('dynamo-fileopd terminated.')

#!/usr/bin/env python

import sys
import logging
import time
import fnmatch
import re
from argparse import ArgumentParser

parser = ArgumentParser(description = 'Update replica information.')
parser.add_argument('--config', '-c', metavar = 'CONFIG', dest = 'config', default = '', help = 'Configuration JSON.')
parser.add_argument('--log-level', '-l', metavar = 'LEVEL', dest = 'log_level', default = 'INFO', help = 'Logging level.')
parser.add_argument('--site', '-s', metavar = 'SITE', dest = 'site', help = 'Do a full update of the site (wildcard allowed).')
parser.add_argument('--dataset', '-d', metavar = 'DATASET', dest = 'dataset', help = 'Do a full update of the dataset (wildcard allowed).')

args = parser.parse_args()
sys.argv = []

## Type of update
delta_update = (not args.site and not args.dataset)

## Set up logging (write to stderr)

log_level = getattr(logging, args.log_level.upper())
log_format = '%(asctime)s:%(levelname)s:%(name)s: %(message)s'

logging.basicConfig(level = log_level, format = log_format)
LOG = logging.getLogger()

## Load and initialize sources

from core.executable import inventory
from dataformat import Configuration, DatasetReplica, ObjectError
import source.impl as sources

config = Configuration(args.config)

LOG.info('Starting inventory update.')

group_source = sources.PhEDExGroupInfoSource(config.groups.config)
site_source = sources.PhEDExSiteInfoSource(config.sites.config)
dataset_source = sources.PhEDExDatasetInfoSource(config.datasets.config)
replica_source = sources.PhEDExReplicaInfoSource(config.replicas.config)

## Refresh groups and sites

LOG.info('Updating list of groups.')
for group in group_source.get_group_list():
    inventory.update(group)

LOG.info('Updating list of sites.')
for site in site_source.get_site_list():
    inventory.update(site)

## Pick up new and changed block replicas

if delta_update:
    ## Normal global delta-update
    ## Get the last update timestamp

    try:
        with open(config.state_file) as source:
            last_update = int(source.read().strip())
    except:
        LOG.error('Failed to retrieve last update timestamp.')
        sys.exit(1)

    update_start = time.time()
    
    ## Fetch the full list of block replicas that were updated since updated_since.
    ## New datasets and blocks will be caught in the process.
    
    LOG.info('Updating list of datasets, blocks, and replicas.')

    new_and_updated_replicas = replica_source.get_updated_replicas(last_update)

else:
    new_and_updated_replicas = replica_source.get_replicas(site = args.site, dataset = args.dataset)
    # Save the embedded versions
    embedded_updated_replicas = set()

## Loop over new and changed block replicas, add them to inventory

for replica in new_and_updated_replicas:
    replica_str = str(replica)

    LOG.debug('Updating %s', replica_str)

    # 0.1: pick up replicas of known groups only
    if replica.group is not None and replica.group.name not in inventory.groups:
        LOG.debug('%s is owned by %s, which is not a tracked group.', replica_str, replica.group.name)
        continue

    # 0.2: Pick up replicas at known sites only
    try:
        site = inventory.sites[replica.site.name]
    except KeyError:
        LOG.debug('%s is at %s, which is not a tracked site.', replica_str, replica.site.name)
        continue

    # 1: Find the dataset in the inventory

    try:
        dataset = inventory.datasets[replica.block.dataset.name]
    except KeyError:
        # If not found, create a new dataset and inject
        LOG.info('Unknown dataset %s. Collecting information.', replica.block.dataset.name)

        dataset_tmp = dataset_source.get_dataset(replica.block.dataset.name)
        if dataset_tmp is None:
            LOG.error('Unknown dataset %s.', replica.block.dataset.name)
            continue

        inventory.update(dataset_tmp)

        # This is the dataset that is embedded in the inventory
        dataset = inventory.datasets[replica.block.dataset.name]

        # Inject blocks as well
        for block in dataset_tmp.blocks:
            inventory.update(block)
    else:
        # If found, update the information (size, last_update, etc.) if necessary
        LOG.debug('Updating information for dataset %s', dataset.name)
        inventory.update(replica.block.dataset)

    # 2: Find the block of the dataset

    block_full_name = replica.block.full_name()
    block = dataset.find_block(replica.block.name)

    if block is None:
        # If not found, create a new block and inject
        LOG.debug('Unknown block %s. Collecting information.', block_full_name)

        block_tmp = dataset_source.get_block(block_full_name, dataset)
        if block_tmp is None:
            LOG.error('Unknown block %s.', block_full_name)
            continue

        inventory.update(block_tmp)

        # This is the block that is embedded in the inventory (`block.dataset` points to `dataset`)
        block = dataset.find_block(replica.block.name)

        dataset.size += block.size
        dataset.num_files += block.num_files

        # Update dataset information
        inventory.update(dataset)
    else:
        # If found, update the information if necessary
        LOG.debug('Updating information for block %s', block_full_name)
        inventory.update(replica.block)

    # 3. Find the dataset replica

    if site.find_dataset_replica(dataset) is None:
        # If not found, create a new replica and inject
        LOG.debug('Creating new replica of %s at %s', dataset.name, site.name)
        inventory.update(DatasetReplica(dataset, site))

    # 4. Update the block replica

    LOG.debug('Updating block replica.')
    embedded_replica = inventory.update(replica)

    if not delta_update:
        embedded_updated_replicas.append(embedded_replica)

## Pick up deleted block replicas

if delta_update:
    # last_update should be available
    deleted_replicas = replica_source.get_deleted_replicas(last_update)

else:
    # Replicas in inventory but not in new_and_updated_replicas are deleted
    deleted_replicas = []

    if args.site:
        site_pat = re.compile(fnmatch.translate(args.site))
    else:
        site_pat = None

    if args.dataset:
        dataset_pat = re.compile(fnmatch.translate(args.dataset))
    else:
        dataset_pat = None

    for site in inventory.sites.itervalues():
        if site_pat and not site_pat.match(site.name):
            continue

        for dataset_replica in site.dataset_replicas():
            if dataset_pat and not dataset_pat.match(dataset_replica.dataset.name):
                continue

            for block_replica in dataset_replica.block_replicas:
                if block_replica not in embedded_updated_replicas:
                    deleted_replicas.append(block_replica)

## Loop over deleted replicas

for replica in deleted_replicas:
    replica_str = str(replica)

    LOG.debug('Deleting %s', replica_str)

    # 0.1: pick up replicas of known groups only
    if replica.group is not None and replica.group.name not in inventory.groups:
        LOG.debug('%s is owned by %s, which is not a tracked group.', replica_str, replica.group.name)
        continue

    # 0.2: Pick up replicas at known sites only
    try:
        site = inventory.sites[replica.site.name]
    except KeyError:
        LOG.debug('%s is at %s, which is not a tracked site.', replica_str, replica.site.name)
        continue

    # 1: Find the dataset in the inventory

    try:
        dataset = inventory.datasets[replica.block.dataset.name]
    except KeyError:
        # If not found, create a new dataset and inject
        LOG.debug('Unknown dataset %s.', dataset.name)
        continue

    # 2: Find the block of the dataset

    block_full_name = replica.block.full_name()
    block = dataset.find_block(replica.block.name)

    if block is None:
        # If not found, create a new block and inject
        LOG.debug('Unknown block %s.', block_full_name)
        continue

    # 3. Find the dataset replica

    if site.find_dataset_replica(dataset) is None:
        LOG.debug('No replica of %s at %s.', dataset.name, site.name)
        continue

    # 4. Delete the block replica

    # blockreplica.delete_from() raises a KeyError or ObjectError if
    # any of the group, site, dataset, ... is not found
    try:
        inventory.delete(replica)
    except KeyError:
        LOG.debug('Replica not found.')
        pass
    except ObjectError:
        LOG.debug('Replica not found.')
        pass

    # 5. Delete the dataset replica if it is empty

    if len(dataset_replica.block_replicas) == 0:
        inventory.delete(dataset_replica)

if delta_update:
    ## Store the timestamp of when we started (allow 1 minute safety margin)
    with open(config.state_file, 'w') as source:
        source.write('%d\n' % (update_start - 60))

LOG.info('Inventory update completed.')

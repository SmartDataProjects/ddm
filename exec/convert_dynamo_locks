#!/usr/bin/env python

## Temporary script to convert web-based locks into registry-based local locks

import sys
import os
import re
import time
import fnmatch

from argparse import ArgumentParser

parser = ArgumentParser(description = 'Convert web-based locks to registry locks')
parser.add_argument('--config', '-c', metavar = 'CONFIG', dest = 'config', required = True, help = 'Configuration JSON.')
parser.add_argument('--test-run', '-T', action = 'store_true', dest = 'test_run', help = 'Do not upload changes to registry.')

args = parser.parse_args()
sys.argv = []

## Load the configuration
from dynamo.dataformat.configuration import Configuration

config = Configuration(args.config)

## Set up logging (write to stdout)
from dynamo.core.executable import make_standard_logger

LOG = make_standard_logger(config.log_level)

## Check if another process is running
process_exists = False

while os.path.exists(config.process_lock):
    try:
        source = open(config.process_lock)
    except (OSError, IOError):
        break

    process_exists = True

    pid = int(source.read().strip())
    source.close()

    try:
        with open('/proc/%d/cmdline' % pid) as proc:
            if not 'dynamod' in proc.read():
                raise Exception()
    except:
        LOG.error('Lock file %s exists but process %d is not a Dynamo process.', config.process_lock, pid)
        os.unlink(config.process_lock)
        process_exists = False
        break

    LOG.info('Another process %d is performing the lock conversion. Waiting for completion.', pid)
    time.sleep(5)

if process_exists:
    LOG.info('Locks are converted by another process. Exiting.')
    sys.exit(0)

with open(config.process_lock, 'w') as process_lock:
    process_lock.write('%d' % os.getpid())

## Start conversion
from dynamo.policy.producers import WebReplicaLock
from dynamo.policy.producers import MySQLReplicaLock
from dynamo.utils.interface.webservice import RESTService, POST
from dynamo.core.executable import inventory
from dynamo.operation.impl.mysqlapplock import MySQLApplicationLockInterface

LOG.info('Translating web-based replica locks into DB-based locks.')

expiry = '2018-04-30'
comment = 'Auto-produced by dynamo'

registry = RESTService(config.weblock)

lock = MySQLApplicationLockInterface(config.applock)
# we don't unlock within this application unless something fails - need to run detox immediately afterwards
lock.lock()

unlocked_datasets = set()

try:
    # we process one source at a time, because each source registers mysql locks as a different user
    for name, source_conf in config.sources.items():
        # first load the existing locks
        instance_conf = Configuration({'db_params': config.mysqllock.db_params, 'users': [[source_conf.user, source_conf.service]]})
        mysqllock = MySQLReplicaLock(instance_conf)
        mysqllock.load(inventory)

        for dataset in inventory.datasets.itervalues():
            try:
                dataset.attr['locked_blocks_original'] = dataset.attr['locked_blocks']
                dataset.attr.pop('locked_blocks')
            except KeyError:
                pass

        LOG.info('Translating ' + name)
    
        instance_conf = Configuration({'sources': {name: source_conf.clone()}, 'auth': config.auth})
    
        weblock = WebReplicaLock(instance_conf)
        weblock.update(inventory)
    
        data = []
        
        for dataset in inventory.datasets.itervalues():
            try:
                locked_blocks = dataset.attr['locked_blocks']
            except KeyError:
                # weblock did not create any lock for this dataset
                try:
                    locked_blocks_original = dataset.attr['locked_blocks_original']
                except KeyError:
                    pass
                else:
                    for site, blocks in locked_blocks_original.iteritems():
                        for block in blocks:
                            block_replica = site.find_block_replica(block)
                            if block_replica is not None:
                                unlocked_datasets.add(site.find_dataset_replica(block.dataset))

                continue

            # check for unlocked block replicas
            try:
                locked_blocks_original = dataset.attr['locked_blocks_original']
            except KeyError:
                pass
            else:
                for site, blocks in locked_blocks_original.iteritems():
                    try:
                        site_locked_blocks = locked_blocks[site]
                    except KeyError:
                        for block in blocks:
                            block_replica = site.find_block_replica(block)
                            if block_replica is not None:
                                unlocked_datasets.add(site.find_dataset_replica(block.dataset))
                    else:
                        for block in blocks:
                            if block not in site_locked_blocks:
                                block_replica = site.find_block_replica(block)
                                if block_replica is not None:
                                    unlocked_datasets.add(site.find_dataset_replica(block.dataset))
       
            entries = []
        
            # if the lock applies to all sites and all blocks of this dataset, we just make one global lock
            collapse_dataset = True
            locked_sites = set()
    
            for site, blocks in locked_blocks.iteritems():
                locked_sites.add(site)
    
                replica = site.find_dataset_replica(dataset)
        
                if blocks == set(br.block for br in replica.block_replicas):
                    entries.append({'item': dataset.name, 'sites': site.name, 'expires': expiry, 'comment': comment})
                else:
                    for block in blocks:
                        entries.append({'item': dataset.name + '#' + block.real_name(), 'sites': site.name, 'expires': expiry, 'comment': comment})
        
                    collapse_dataset = False
    
            if locked_sites != set(r.site for r in dataset.replicas):
                collapse_dataset = False
        
            if collapse_dataset:
                # replace entries with a single-element list
                entries = [{'item': dataset.name, 'expires': expiry, 'comment': comment}]
        
            data.extend(entries)
            
        # cleanup
        for dataset in inventory.datasets.itervalues():
            try:
                dataset.attr.pop('locked_blocks')
            except KeyError:
                pass
            try:
                dataset.attr.pop('locked_blocks_original')
            except KeyError:
                pass
    
        LOG.info('Sending %d datasets and blocks to registry frontend', len(data))
    
        if args.test_run:
            LOG.info('Not sending data to registry.')
        else:
            request_url = 'set?asuser=%s&service=%s' % (source_conf.user, source_conf.service)
            registry.make_request(request_url, method = POST, options = data, format = 'json')
    
    # Intentionally removing the file only when everything succeeds
    os.unlink(config.process_lock)

finally:
    lock.unlock()

# update block replicas that got unlocked
from dynamo.source.impl import PhEDExReplicaInfoSource

replica_source = PhEDExReplicaInfoSource(config.replica_source)

for dataset_replica in unlocked_datasets:
    dataset = dataset_replica.dataset
    site = dataset_replica.site

    source_reps = replica_source.get_replicas(dataset = dataset.name, site = site.name)
    if len(source_reps) == 0:
        # not good but fine
        continue

    block_names = set(brep.block.name for brep in dataset_replica.block_replicas)

    for rep in source_reps:
        if rep.block.name in block_names:
            inventory.update(rep)

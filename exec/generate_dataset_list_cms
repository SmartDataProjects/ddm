#!/usr/bin/env python

import sys
import sqlite3

from argparse import ArgumentParser

parser = ArgumentParser(description = 'Update datasets, blocks, and files information.')
parser.add_argument('--config', '-c', metavar = 'CONFIG', dest = 'config', default = '', help = 'Configuration JSON.')
parser.add_argument('--log-level', '-l', metavar = 'LEVEL', dest = 'log_level', default = 'INFO', help = 'Logging level.')

args = parser.parse_args()
sys.argv = []

## Load the configuration
from dynamo.dataformat import Configuration

config = Configuration(args.config)

## Set up logging (write to stdout)
log_level = getattr(logging, config.log_level.upper())
log_format = '%(asctime)s:%(levelname)s:%(name)s: %(message)s'

# Everything above log_level goes to stdout
out_handler = logging.StreamHandler(sys.stdout)
out_handler.setLevel(log_level)
out_handler.setFormatter(logging.Formatter(fmt = log_format))
# If >= ERROR, goes also to stderr
err_handler = logging.StreamHandler(sys.stderr)
err_handler.setLevel(logging.ERROR)
err_handler.setFormatter(logging.Formatter(fmt = log_format))

LOG = logging.getLogger()
LOG.setLevel(log_level)
LOG.addHandler(out_handler)
LOG.addHandler(err_handler)

## If the dataset list already exists, quit
if os.path.exists(config.dataset_state_file):
    LOG.info('Dataset list exists.')
    sys.exit(0)

## Load and initialize sources
import dynamo.source.impl as sources

config.datasets.config.phedex = config.phedex

dataset_source = sources.PhEDExDatasetInfoSource(config.datasets.config)

all_datasets = dataset_source.get_dataset_names(include = ['*'])

state_db = sqlite3.connect(config.dataset_state_file)
state_db.execute('CREATE TABLE `datasets` (`id` INTEGER NOT NULL PRIMARY KEY, `name` TEXT NOT NULL)')

sql = 'INSERT INTO `datasets` (`name`) VALUES (?)'
cursor = state_db.cursor()
for dataset in all_datasets:
    cursor.execute(sql, (dataset,))

cursor.close()
state_db.close()
